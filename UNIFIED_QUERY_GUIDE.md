# Unified Natural Language Query Flow - Implementation Guide

## Overview

This guide documents the **Unified Query Flow** feature that enables users to search plasma physics literature using natural language queries. The system intelligently extracts parameters, generates SPARQL queries, and returns relevant papers.

## Architecture

```
User Query â†’ NLP Parser â†’ SPARQL Builder â†’ Knowledge Graph â†’ Results
     â†“            â†“              â†“               â†“            â†“
  "Find...   Parameters    Dynamic Query    Fuseki      Papers List
   papers"   Extraction     Generation      SPARQL
```

### Components

1. **NLP Query Processor** (`backend/nlp_query_processor.py`)
   - Parses natural language using LLM (GPT-4o-mini)
   - Extracts parameters (temperature, density ranges)
   - Identifies temporal constraints and keywords
   - Normalizes units automatically

2. **Dynamic SPARQL Builder** (`backend/query_builder.py`)
   - Constructs SPARQL queries from parsed parameters
   - Handles complex filters (ranges, keywords, dates)
   - Optimized for performance

3. **Unified Search API** (`backend/main.py`)
   - REST endpoint: `POST /query/natural-language`
   - Processes queries end-to-end
   - Returns structured results with metadata

4. **Frontend Component** (`frontend/src/components/UnifiedSearch.tsx`)
   - Natural language search interface
   - Shows parsed query for transparency
   - Displays results with links to arXiv

## Quick Start

### 1. Setup (one-time)

```bash
# Ensure OpenAI API key is set
export OPENAI_API_KEY="your-api-key-here"

# Or add to .env file
echo "OPENAI_API_KEY=your-api-key" >> .env

# Install dependencies (if not already done)
pip install openai python-dotenv pydantic
```

### 2. Start Services

```bash
# Terminal 1: Start Fuseki (knowledge graph)
bash scripts/setup_fuseki.sh

# Terminal 2: Start backend API
cd backend
python run.py

# Terminal 3: Start frontend
cd frontend
npm run dev
```

### 3. Test the System

```bash
# Run automated tests
python test_unified_query.py
```

### 4. Use the UI

1. Open http://localhost:5173
2. Try example queries:
   - "Show me recent research on electron density between 10^16 and 10^18 m^-3"
   - "Find papers with temperature above 10 keV"
   - "Recent tokamak experiments"

## Example Queries

### Temperature Queries
```
âœ… "Find papers with temperature above 10 keV"
âœ… "Show me high-temperature plasmas between 5 and 15 keV"
âœ… "Papers with electron temperature measurements"
âœ… "Low temperature plasmas under 1 keV"
```

### Density Queries
```
âœ… "Electron density between 10^16 and 10^18 m^-3"
âœ… "Show me papers with density measurements"
âœ… "High density plasmas above 10^20 m^-3"
âœ… "Papers with both density and temperature data"
```

### Combined Queries
```
âœ… "Recent research on high-temperature, high-density plasmas"
âœ… "Tokamak experiments from 2023 with temperature above 5 keV"
âœ… "Low-temperature plasmas with density between 10^17 and 10^19"
```

### Keyword Queries
```
âœ… "Recent tokamak papers"
âœ… "Research on plasma confinement"
âœ… "Papers about electron temperature in fusion devices"
```

## API Reference

### Endpoint

```http
POST /query/natural-language
Content-Type: application/json

{
  "query": "Find papers with temperature above 10 keV",
  "limit": 20,
  "include_sparql": false
}
```

### Request Schema

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `query` | string | Yes | Natural language query (min 3 chars) |
| `limit` | integer | No | Max results (1-100, default: 20) |
| `include_sparql` | boolean | No | Include generated SPARQL in response |

### Response Schema

```json
{
  "parsed_query": {
    "intent": "search",
    "parameters": {
      "temperature": {
        "type": "temperature",
        "min_value": 10.0,
        "max_value": null,
        "unit": "keV",
        "normalized_min": 10.0,
        "normalized_max": null
      }
    },
    "keywords": ["plasma"],
    "temporal_constraint": null,
    "confidence": 0.9,
    "original_query": "Find papers with temperature above 10 keV"
  },
  "papers": [
    {
      "arxiv_id": "2310.12345",
      "title": "High Temperature Plasma Experiments...",
      "authors": "Smith, J., Doe, A.",
      "publication_date": "2023-10-15"
    }
  ],
  "total_results": 5,
  "generated_sparql": "PREFIX : <http://example.org/plasma#>...",
  "execution_time_ms": 245.67
}
```

## How It Works

### Step 1: Natural Language Parsing

**Input:**
```
"Show me recent research on electron density between 10^16 and 10^18 m^-3"
```

**Parsed Output:**
```json
{
  "intent": "search",
  "parameters": {
    "density": {
      "min_value": 1e16,
      "max_value": 1e18,
      "unit": "m^-3",
      "normalized_min": 1e16,
      "normalized_max": 1e18
    }
  },
  "keywords": ["electron", "density"],
  "temporal_constraint": "recent",
  "confidence": 0.9
}
```

### Step 2: SPARQL Generation

The system generates a SPARQL query:

```sparql
PREFIX : <http://example.org/plasma#>

SELECT DISTINCT ?paper ?title ?authors ?publicationDate
                ?densValue ?densUnit ?densNormalized
WHERE {
  ?paper a :Paper ;
         :title ?title ;
         :authors ?authors ;
         :publicationDate ?publicationDate .

  # Density filter
  ?paper :reports ?densMeas .
  ?densMeas :measuresParameter ?dens .
  ?dens a :Density ;
        :value ?densValue ;
        :unitString ?densUnit ;
        :normalizedValue ?densNormalized .
  FILTER(?densNormalized >= 1e16 && ?densNormalized <= 1e18)

  # Temporal filter (recent = last 2 years)
  FILTER(?publicationDate >= "2023-01-01"^^xsd:date)

  # Keyword filter
  FILTER(REGEX(?title, "electron|density", "i"))
}
ORDER BY DESC(?publicationDate)
LIMIT 20
```

### Step 3: Execution & Results

The query is executed against the Fuseki knowledge graph, and results are formatted for the frontend.

## Configuration

### LLM Settings

Edit `backend/nlp_query_processor.py`:

```python
# Change model for different speed/cost tradeoffs
model="gpt-4o-mini",  # Fast & cheap (default)
# model="gpt-4",      # More accurate but slower/pricier
```

### Unit Normalization

Temperature normalization (â†’ keV):
- `eV` â†’ multiply by 0.001
- `K` â†’ multiply by 8.617e-8
- `keV` â†’ no change

Density normalization (â†’ mâ»Â³):
- `cmâ»Â³` â†’ multiply by 1e6
- `mâ»Â³` â†’ no change

### Query Defaults

Edit `backend/query_builder.py`:

```python
# Change "recent" definition
cutoff_date = (datetime.now() - timedelta(days=730))  # 2 years

# Adjust result limits
query += f"LIMIT {limit}"  # Default: 20
```

## Troubleshooting

### Issue: "No OpenAI API key found"

**Solution:**
```bash
export OPENAI_API_KEY="sk-..."
# Or add to .env file
echo "OPENAI_API_KEY=sk-..." >> .env
```

### Issue: "Failed to connect to Fuseki"

**Solution:**
```bash
# Check if Fuseki is running
curl http://localhost:3030/$/ping

# If not, start it
bash scripts/setup_fuseki.sh
```

### Issue: "No results found"

**Possible causes:**
1. Query parameters too restrictive
2. Knowledge graph has limited data
3. Parameter extraction failed

**Debug:**
```bash
# Enable SPARQL debugging
curl -X POST http://localhost:8000/query/natural-language \
  -H "Content-Type: application/json" \
  -d '{"query": "your query", "include_sparql": true}' \
  | jq '.generated_sparql'
```

### Issue: Frontend TypeScript errors

**Solution:**
```bash
cd frontend
npm install
# Check for type errors
npm run type-check
```

## Testing

### Unit Tests

```bash
# Test NLP parsing
python -c "from backend.nlp_query_processor import NLPQueryProcessor; \
  p = NLPQueryProcessor(); \
  print(p.parse('temperature above 10 keV'))"

# Test SPARQL generation
python test_unified_query.py
```

### Integration Tests

```bash
# Test full pipeline (requires running services)
curl -X POST http://localhost:8000/query/natural-language \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Find papers with temperature above 10 keV",
    "limit": 5,
    "include_sparql": true
  }' | jq .
```

### Frontend Tests

```bash
cd frontend
npm run test  # If you add tests
```

## Performance

### Benchmarks

| Component | Typical Time |
|-----------|--------------|
| LLM Parsing | 200-500ms |
| SPARQL Generation | <10ms |
| Query Execution | 50-200ms (cached: <5ms) |
| **Total** | **~300-700ms** |

### Optimization Tips

1. **Enable caching:** Already enabled by default (300s TTL)
2. **Use smaller LLM:** `gpt-4o-mini` instead of `gpt-4`
3. **Limit results:** Use `limit` parameter effectively
4. **Fallback to regex:** Set `use_llm=False` for regex-only (faster but less accurate)

## Future Enhancements

### Planned Features

- [ ] Multi-language support
- [ ] Query suggestions based on history
- [ ] Saved/favorite queries
- [ ] Result visualization (charts, graphs)
- [ ] More parameter types (pressure, magnetic field)
- [ ] Boolean logic (AND/OR/NOT)
- [ ] Export results (CSV, JSON, BibTeX)

### Advanced Queries (Future)

```
ðŸš§ "Compare temperature measurements across tokamak vs stellarator"
ðŸš§ "Show me trends in electron density over the last decade"
ðŸš§ "Papers similar to arXiv:2310.12345"
ðŸš§ "Authors who published on high-temperature plasmas"
```

## Demo for Job Application

### 1. Start the Demo

```bash
# Quick startup script
./scripts/start_demo.sh  # TODO: Create this

# Or manual startup
bash scripts/setup_fuseki.sh
cd backend && python run.py &
cd frontend && npm run dev
```

### 2. Showcase Features

**Show these queries in sequence:**

1. **Simple query:**
   ```
   "Find papers with temperature above 10 keV"
   ```

2. **Complex range query:**
   ```
   "Show me recent research on electron density between 10^16 and 10^18 m^-3"
   ```

3. **Multi-parameter query:**
   ```
   "Recent tokamak experiments with high temperature and high density"
   ```

4. **Keyword search:**
   ```
   "Papers about plasma confinement in fusion devices"
   ```

### 3. Highlight Technical Skills

- âœ… **LLM Integration:** GPT-4o-mini for parameter extraction
- âœ… **Semantic Web:** SPARQL + RDF knowledge graph
- âœ… **Full-Stack:** FastAPI backend + React frontend
- âœ… **Unit Handling:** Automatic normalization
- âœ… **Real-time:** Sub-second query processing
- âœ… **Transparency:** Shows parsed query and generated SPARQL

## Resources

- [Backend API Docs](http://localhost:8000/docs)
- [OpenAI API](https://platform.openai.com/docs)
- [SPARQL Tutorial](https://www.w3.org/TR/sparql11-query/)
- [Apache Jena Fuseki](https://jena.apache.org/documentation/fuseki2/)

## Support

For issues or questions:
1. Check logs: `backend/logs/` (if configured)
2. Enable debug mode: Set `DEBUG=True` in backend config
3. Review this guide's troubleshooting section

---

**Status:** âœ… Complete and ready for demo!

**Last Updated:** 2025-10-30
